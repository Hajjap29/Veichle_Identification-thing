{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2268593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# The dotenv library is only needed if you are loading the .env file locally.\n",
    "# If you are deploying on Streamlit Cloud and using st.secrets, you won't need this.\n",
    "from dotenv import load_dotenv \n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Load environment variables from a local .env file (explicit path)\n",
    "load_dotenv(dotenv_path=r\"D:\\Project for fun\\Car Model Recognition\\notebooks\\.env\") \n",
    "\n",
    "# ðŸ›¡ï¸ SECURE: Get the key only from the environment\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") \n",
    "\n",
    "MODEL = \"gpt-4o-mini\" \n",
    "\n",
    "# âš ï¸ Important: The standard OpenAI API URL for Chat Completions is generally /v1/chat/completions \n",
    "# or /v1/images/generations. The endpoint /v1/responses is non-standard or might be incorrect.\n",
    "# For a standard call (assuming you're using chat/vision):\n",
    "API_URL = \"https://api.openai.com/v1/chat/completions\" \n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Now you can use HEADERS in your API call..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39235679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a8bd6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_file_to_data_uri(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    b64 = base64.b64encode(data).decode(\"utf-8\")\n",
    "    # Try to infer mime type from extension (very simple)\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    mime = \"image/jpeg\"\n",
    "    if ext in [\".png\"]:\n",
    "        mime = \"image/png\"\n",
    "    elif ext in [\".webp\"]:\n",
    "        mime = \"image/webp\"\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "# Quick test\n",
    "# data_uri = image_file_to_data_uri(\"example.jpg\")\n",
    "# print(data_uri[:200])  # preview start (do not print full binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "32f138f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_JSON = \"\"\"\n",
    "You are an image-understanding assistant. I will provide an image. \n",
    "Respond ONLY with JSON (no extra text). The JSON must have the following keys:\n",
    "- make: string or null\n",
    "- model: string or null\n",
    "- year_range: string or null (e.g., \"2016-2020\")\n",
    "- vehicle_class: one of [\"compact\", \"midsize\", \"fullsize\", \"suv\", \"pickup\", \"van\", \"motorcycle\", \"bus\", \"truck\", \"unknown\"]\n",
    "- powertrain: one of [\"gasoline\", \"diesel\", \"hybrid\", \"plug-in hybrid\", \"electric\", \"unknown\"]\n",
    "- confidence: number between 0 and 1 (estimate of how confident you are)\n",
    "\n",
    "Make conservative guesses. If uncertain, put null or \"unknown\". Don't output any explanatory text â€” ONLY the JSON object.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "155a2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_vision_api_with_image(data_uri, prompt_text=PROMPT_JSON, model=MODEL):\n",
    "    \"\"\"\n",
    "    Sends the image (as a data URI) and prompt to the Responses API.\n",
    "    Returns the raw text output (we'll parse JSON out of it).\n",
    "    \"\"\"\n",
    "    # Build the request body in a compact \"input\" form.\n",
    "    # Many example doc patterns send a list with an image content block together\n",
    "    # with a text block. The exact schema may vary slightlyâ€”check docs if you get errors.\n",
    "    body = {\n",
    "        \"model\": model,\n",
    "        \"input\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"input_text\", \"text\": prompt_text},\n",
    "                    {\"type\": \"input_image\", \"image_url\": data_uri}\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    resp = requests.post(API_URL, headers=HEADERS, json=body, timeout=60)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "# Example call:\n",
    "# data_uri = image_file_to_data_uri(\"car_photo.jpg\")\n",
    "# r = call_vision_api_with_image(data_uri)\n",
    "# print(json.dumps(r, indent=2)[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb96483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_from_response(resp_json):\n",
    "    \"\"\"Robustly extracts the first JSON object from likely text fields in the API response.\n",
    "    Prefers structured 'output' content, falls back to 'choices' and then the full dump.\n",
    "    Uses json.JSONDecoder().raw_decode to find the first valid object substring.\n",
    "    Returns a dict (parsed JSON) or {'raw_text':..., 'error':...}.\"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    # 1) Check Responses API 'output' shape for message/content blocks\n",
    "    try:\n",
    "        if isinstance(resp_json.get(\"output\"), list):\n",
    "            for item in resp_json.get(\"output\", []):\n",
    "                if item.get(\"type\") == \"message\":\n",
    "                    for c in item.get(\"content\", []):\n",
    "                        # handle 'output_text' or simple 'text' keys\n",
    "                        if isinstance(c, dict):\n",
    "                            txt = c.get(\"text\") or c.get(\"content\") or None\n",
    "                            if isinstance(txt, str):\n",
    "                                candidates.append(txt)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) Fallback: older 'choices' shape\n",
    "    if not candidates and \"choices\" in resp_json:\n",
    "        try:\n",
    "            choice_msg = resp_json[\"choices\"][0].get(\"message\", {}).get(\"content\")\n",
    "            if isinstance(choice_msg, str):\n",
    "                candidates.append(choice_msg)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 3) Final fallback: stringify the whole response\n",
    "    if not candidates:\n",
    "        candidates.append(json.dumps(resp_json))\n",
    "\n",
    "    full_text = \"\\n\".join(candidates)\n",
    "\n",
    "    # Attempt to find the first JSON object substring using a raw_decode scan\n",
    "    decoder = json.JSONDecoder()\n",
    "    text = full_text\n",
    "    for i in range(len(text)):\n",
    "        try:\n",
    "            obj, idx = decoder.raw_decode(text[i:])\n",
    "            if isinstance(obj, dict):\n",
    "                return obj\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "    return {\"raw_text\": full_text, \"error\": \"no JSON object found\"}\n",
    "\n",
    "# Example usage:\n",
    "# parsed = extract_json_from_response(r)\n",
    "# print(parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a9424410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple mapping from coarse class â†’ lifetime CO2e range (tons CO2e)\n",
    "# These numbers are illustrative; refine with GREET/ICCT or regional data.\n",
    "CARBON_TABLE = {\n",
    "    \"compact\":    {\"lifetime_tons_min\": 30, \"lifetime_tons_max\": 50},\n",
    "    \"midsize\":    {\"lifetime_tons_min\": 40, \"lifetime_tons_max\": 65},\n",
    "    \"fullsize\":   {\"lifetime_tons_min\": 55, \"lifetime_tons_max\": 85},\n",
    "    \"suv\":        {\"lifetime_tons_min\": 50, \"lifetime_tons_max\": 80},\n",
    "    \"pickup\":     {\"lifetime_tons_min\": 60, \"lifetime_tons_max\": 100},\n",
    "    \"van\":        {\"lifetime_tons_min\": 45, \"lifetime_tons_max\": 80},\n",
    "    \"motorcycle\": {\"lifetime_tons_min\": 10, \"lifetime_tons_max\": 25},\n",
    "    \"bus\":        {\"lifetime_tons_min\": 150, \"lifetime_tons_max\": 400},\n",
    "    \"truck\":      {\"lifetime_tons_min\": 120, \"lifetime_tons_max\": 350},\n",
    "    \"unknown\":    {\"lifetime_tons_min\": None, \"lifetime_tons_max\": None}\n",
    "}\n",
    "\n",
    "def estimate_carbon_from_detection(detection):\n",
    "    # detection is the parsed JSON from the model\n",
    "    cls = detection.get(\"vehicle_class\", \"unknown\")\n",
    "    powertrain = detection.get(\"powertrain\", \"unknown\")\n",
    "    cfg = CARBON_TABLE.get(cls, CARBON_TABLE[\"unknown\"])\n",
    "    # Optionally adjust EVs / hybrids: EVs have higher manufacturing but lower use-phase\n",
    "    if powertrain == \"electric\" and cls != \"unknown\":\n",
    "        # approximate adjustment for EV: slightly lower lifetime for many contexts (refine as needed)\n",
    "        # shift the min/max down by ~20% after manufacturing accounted separately (illustrative)\n",
    "        if cfg[\"lifetime_tons_min\"] is not None:\n",
    "            min_est = max(0, int(cfg[\"lifetime_tons_min\"] * 0.7))\n",
    "            max_est = int(cfg[\"lifetime_tons_max\"] * 0.8)\n",
    "            return {\"lifetime_min_tons\": min_est, \"lifetime_max_tons\": max_est, \"note\": \"EV estimate; grid dependency not included\"}\n",
    "    return {\"lifetime_min_tons\": cfg[\"lifetime_tons_min\"], \"lifetime_max_tons\": cfg[\"lifetime_tons_max\"], \"note\": \"category-level estimate\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "760ffd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_file(path):\n",
    "    print(\"Encoding image...\")\n",
    "    data_uri = image_file_to_data_uri(path)\n",
    "    print(\"Calling vision API...\")\n",
    "    resp = call_vision_api_with_image(data_uri)\n",
    "    print(\"API returned; extracting JSON...\")\n",
    "    parsed = extract_json_from_response(resp)\n",
    "    print(\"Parsed detection:\", parsed)\n",
    "    est = estimate_carbon_from_detection(parsed if isinstance(parsed, dict) else {})\n",
    "    result = {\"detection\": parsed, \"carbon_estimate\": est}\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# result = analyze_image_file(\"my_car_photo.jpg\")\n",
    "# print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c23d92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refined_estimate_from_user_inputs(detection, miles_per_year=None, years=None, regional_grid_emissions=None):\n",
    "    \"\"\"Refine lifetime estimate using optional user inputs.\n",
    "\n",
    "    Approach:\n",
    "    - mid_lifetime (tons) is midpoint from CARBON_TABLE\n",
    "    - manufacturing = 30% of mid_lifetime, use_phase_total = 70%\n",
    "    - if `miles_per_year` and `years` provided, compute per-mile and annual use-phase estimates\n",
    "    \"\"\"\n",
    "    cls = (detection or {}).get(\"vehicle_class\", \"unknown\")\n",
    "    cfg = CARBON_TABLE.get(cls, {})\n",
    "    if not cfg or cfg.get(\"lifetime_tons_min\") is None:\n",
    "        return {\"error\": \"Cannot estimate; unknown class\"}\n",
    "\n",
    "    mid_lifetime = (cfg[\"lifetime_tons_min\"] + cfg[\"lifetime_tons_max\"]) / 2.0\n",
    "    manufacturing = mid_lifetime * 0.3\n",
    "    use_phase_total = mid_lifetime * 0.7  # tons over lifetime\n",
    "\n",
    "    result = {\n",
    "        \"manufacturing_tons\": manufacturing,\n",
    "        \"use_phase_total_tons\": use_phase_total,\n",
    "    }\n",
    "\n",
    "    if miles_per_year and years:\n",
    "        lifetime_miles = miles_per_year * years\n",
    "        per_mile_tons = (use_phase_total / lifetime_miles) if lifetime_miles > 0 else None\n",
    "        annual_emissions_tons = (per_mile_tons * miles_per_year) if per_mile_tons is not None else (use_phase_total / years)\n",
    "        lifetime_estimate = manufacturing + annual_emissions_tons * years\n",
    "        # also provide per-mile in grams for easier interpretation (1 ton = 1e6 grams)\n",
    "        per_mile_g = per_mile_tons * 1e6 if per_mile_tons is not None else None\n",
    "\n",
    "        result.update({\n",
    "            \"per_mile_tons\": per_mile_tons,\n",
    "            \"per_mile_g\": per_mile_g,\n",
    "            \"use_phase_est_annual_tons\": annual_emissions_tons,\n",
    "            \"estimated_lifetime_tons\": lifetime_estimate,\n",
    "            \"note\": \"Estimates are illustrative. For EVs, grid intensity affects use-phase.\",\n",
    "        })\n",
    "    else:\n",
    "        result[\"note\"] = \"Provide miles_per_year and years to refine per-mile and annual estimates.\"\n",
    "\n",
    "    # If regional_grid_emissions provided and detection indicates electric, add a note (no calculation here).\n",
    "    if regional_grid_emissions is not None and (detection or {}).get(\"powertrain\") == \"electric\":\n",
    "        result[\"grid_emissions_note\"] = \"Regional grid CO2 intensity provided; consider integrating it into EV use-phase calculation.\"\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70064305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test 1: structured output message with JSON in text ---\n",
      "{'make': 'Toyota', 'model': None, 'year_range': '2016-2020', 'vehicle_class': 'midsize', 'powertrain': 'gasoline', 'confidence': 0.8}\n",
      "--- Test 2: choices-style response with JSON embedded ---\n",
      "{'make': 'Honda', 'model': None, 'year_range': None, 'vehicle_class': 'compact', 'powertrain': 'diesel', 'confidence': 0.6}\n",
      "Refined estimate (miles_per_year=12000, years=12):\n",
      "{'manufacturing_tons': 15.75, 'use_phase_total_tons': 36.75, 'per_mile_tons': 0.0002552083333333333, 'per_mile_g': 255.20833333333331, 'use_phase_est_annual_tons': 3.0624999999999996, 'estimated_lifetime_tons': 52.49999999999999, 'note': 'Estimates are illustrative. For EVs, grid intensity affects use-phase.'}\n"
     ]
    }
   ],
   "source": [
    "# Test extract_json_from_response with canned Responses API shapes\n",
    "sample_resp_1 = {\n",
    "    'output': [\n",
    "        {'type': 'message', 'content': [{'type': 'output_text', 'text': '{\"make\":\"Toyota\",\"model\":null,\"year_range\":\"2016-2020\",\"vehicle_class\":\"midsize\",\"powertrain\":\"gasoline\",\"confidence\":0.8}'}]}\n",
    "    ]\n",
    "}\n",
    "# Use a single-quoted string with explicit \\n for newlines and valid JSON embedded\n",
    "sample_resp_2 = {\n",
    "    'choices': [\n",
    "        {\n",
    "            'message': {\n",
    "                'content': 'Intro text\\n{\"make\":\"Honda\",\"model\":null,\"year_range\":null,\"vehicle_class\":\"compact\",\"powertrain\":\"diesel\",\"confidence\":0.6}\\nThanks'\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print('--- Test 1: structured output message with JSON in text ---')\n",
    "print(extract_json_from_response(sample_resp_1))\n",
    "print('--- Test 2: choices-style response with JSON embedded ---')\n",
    "print(extract_json_from_response(sample_resp_2))\n",
    "\n",
    "# Demonstrate refined estimate using the parsed detection (no API call required)\n",
    "parsed = extract_json_from_response(sample_resp_1)\n",
    "if isinstance(parsed, dict) and parsed.get('vehicle_class'):\n",
    "    print('Refined estimate (miles_per_year=12000, years=12):')\n",
    "    print(refined_estimate_from_user_inputs(parsed, miles_per_year=12000, years=12))\n",
    "else:\n",
    "    print('Parsing failed; parsed object:', parsed)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
